{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\n","# Set display option back to default\n","pd.set_option('display.max_columns', None)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["--------------------------\n","Pipeline Script \n","Last Update: 3/3/2024 \n","-------------------------- \n","\n","\n","--------------------------\n","( 1 ) Creating 'temp' Folder\n","--------------------------\n","\n","Copying raw_data to temp folder...\n","Copying completed.\n","--------------------------\n","( 2 ) Preparing PyLabel COCO Dataset\n","--------------------------\n","\n","\n","\n","Preprocessing user_1-pre...\n","Number of images: 2675\n","Number of classes: 3\n","Classes:['undamagedresidentialbuilding', 'undamagedcommercialbuilding']\n","Class counts:\n","cat_name\n","NaN                             2579\n","undamagedresidentialbuilding    1869\n","undamagedcommercialbuilding      224\n","Name: count, dtype: int64\n","Path to annotations:\n","d:\\GitHub_Repo\\EY_Competition\\storm-assessment-clean\\temp\\pre_event\n","\n","\n","Preprocessing user_1-post...\n","Number of images: 2682\n","Number of classes: 5\n","Classes:['undamagedresidentialbuilding', 'damagedresidentialbuilding', 'undamagedcommercialbuilding', 'damagedcommercialbuilding']\n","Class counts:\n","cat_name\n","undamagedresidentialbuilding    5077\n","NaN                             2083\n","undamagedcommercialbuilding     1660\n","damagedresidentialbuilding       785\n","damagedcommercialbuilding        199\n","Name: count, dtype: int64\n","Path to annotations:\n","d:\\GitHub_Repo\\EY_Competition\\storm-assessment-clean\\temp\\post_event\n","\n","\n","user_2-pre.json Not Found.\n"," Skipping...\n","\n","\n","\n","\n","user_2-post.json Not Found.\n"," Skipping...\n","\n","\n","\n","\n","Preprocessing user_3-pre...\n","Number of images: 2682\n","Number of classes: 3\n","Classes:['undamagedresidentialbuilding', 'undamagedcommercialbuilding']\n","Class counts:\n","cat_name\n","NaN                             2671\n","undamagedresidentialbuilding     259\n","undamagedcommercialbuilding       35\n","Name: count, dtype: int64\n","Path to annotations:\n","d:\\GitHub_Repo\\EY_Competition\\storm-assessment-clean\\temp\\pre_event\n","\n","\n","user_3-post.json Not Found.\n"," Skipping...\n","\n","\n","\n","\n","Preprocessing user_4-pre...\n","Number of images: 2682\n","Number of classes: 3\n","Classes:['undamagedresidentialbuilding', 'undamagedcommercialbuilding']\n","Class counts:\n","cat_name\n","NaN                             2674\n","undamagedresidentialbuilding      67\n","undamagedcommercialbuilding       24\n","Name: count, dtype: int64\n","Path to annotations:\n","d:\\GitHub_Repo\\EY_Competition\\storm-assessment-clean\\temp\\pre_event\n","\n","\n","Preprocessing user_4-post...\n","Number of images: 2682\n","Number of classes: 4\n","Classes:['damagedresidentialbuilding', 'undamagedcommercialbuilding', 'damagedcommercialbuilding']\n","Class counts:\n","cat_name\n","NaN                            2646\n","damagedresidentialbuilding       94\n","damagedcommercialbuilding        24\n","undamagedcommercialbuilding       3\n","Name: count, dtype: int64\n","Path to annotations:\n","d:\\GitHub_Repo\\EY_Competition\\storm-assessment-clean\\temp\\post_event\n","--------------------------\n","( 3 ) Creating Dataset\n","--------------------------\n","\n","Number of images before dropna: 13403\n","Number of images after dropna: 750\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13560\\1175146839.py:105: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  combined_df.sort_values(by='img_filename', inplace=True)\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------\n","( 4 ) Splitting Dataset\n","--------------------------\n","\n","--------------------------\n","( 5 ) Checking Splits Statistics\n","--------------------------\n","\n","\n","\n","\n","--------------------------\n","( 6 ) Dataset Statistics\n","--------------------------\n","\n","Number of images: 750\n","Number of classes: 4\n","Classes:['undamagedresidentialbuilding', 'damagedresidentialbuilding', 'undamagedcommercialbuilding', 'damagedcommercialbuilding']\n","Class counts:\n","cat_name\n","undamagedresidentialbuilding    7272\n","undamagedcommercialbuilding     1946\n","damagedresidentialbuilding       879\n","damagedcommercialbuilding        223\n","Name: count, dtype: int64\n","Path to annotations:\n","\n","\n","\n","\n","--------------------------\n","( 7 ) COCO to YOLO\n","--------------------------\n","\n","Exporting to YOLO format...\n"]},{"name":"stderr","output_type":"stream","text":["Exporting YOLO files...: 100%|██████████| 750/750 [00:10<00:00, 70.63it/s]\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------\n","Pipeline Script End\n","--------------------------\n","\n"]}],"source":["import os\n","import pandas as pd\n","import shutil\n","import warnings\n","from pylabel import importer\n","from collections import Counter\n","from pylabel.dataset import Dataset\n","\n","class CocoDatasetProcessor:\n","    \"\"\"\n","    Class to process COCO datasets and perform various operations.\n","    \"\"\"\n","\n","    def __init__(self, home):\n","        \"\"\"\n","        Initialize the CocoDatasetProcessor object.\n","\n","        Parameters:\n","        - home (str): The path to the home directory.\n","        \"\"\"\n","        self.home = home\n","\n","    def rename_images_with_suffix(self, directory, suffix):\n","        \"\"\"\n","        Rename images in a directory by adding a suffix to their filenames.\n","\n","        Parameters:\n","        - directory (str): The path to the directory containing images.\n","        - suffix (str): The suffix to be added to the filenames.\n","        \"\"\"\n","        for filename in os.listdir(directory):\n","            if filename.endswith(\".jpg\"):\n","                old_path = os.path.join(directory, filename)\n","                new_filename = f\"{suffix}_{filename}\"\n","                new_path = os.path.join(directory, new_filename)\n","                os.rename(old_path, new_path)\n","\n","    def coco_importer(self, annots_json, path_to_images, name):\n","        \"\"\"\n","        Create a COCO PyLabel dataset.\n","\n","        Parameters:\n","        - annots_json (str): The path to the COCO format annotations JSON file.\n","        - path_to_images (str): The path to the directory containing images.\n","        - name (str): The name of the dataset.\n","\n","        Returns:\n","        - Dataset: The dataset in COCO PyLabel format.\n","        \"\"\"\n","        dataset = importer.ImportCoco(annots_json, path_to_images=path_to_images, name=name)\n","        return dataset\n","\n","    def prepare_coco_dataset(self, path_to_annots_json, path_to_images, user, suffix):\n","        \"\"\"\n","        Prepare a COCO dataset for further processing.\n","\n","        Parameters:\n","        - path_to_annots_json (str): The path to the COCO format annotations JSON file.\n","        - path_to_images (str): The path to the directory containing images.\n","        - user (str): The user identifier.\n","        - suffix (str): The suffix indicating pre/post event.\n","\n","        Returns:\n","        - Dataset: The prepared Pylabel dataset.\n","        \"\"\"\n","        print(\"\\n\")\n","        print(f\"Preprocessing {user}-{suffix}...\")\n","\n","        # Create a COCO PyLabel dataset\n","        annots_dataset = self.coco_importer(path_to_annots_json, path_to_images, name=\"annots_coco\")\n","\n","        # Mapping of cat_id to cat_name\n","        cat_name_mapping = {\n","            '1': 'undamagedresidentialbuilding',\n","            '2': 'damagedresidentialbuilding',\n","            '3': 'undamagedcommercialbuilding',\n","            '4': 'damagedcommercialbuilding'\n","        }\n","\n","        # Append cat_name based on cat_id\n","        annots_dataset.df['cat_name'] = annots_dataset.df['cat_id'].map(cat_name_mapping)\n","\n","        print(f\"Number of images: {annots_dataset.analyze.num_images}\")\n","        print(f\"Number of classes: {annots_dataset.analyze.num_classes}\")\n","        print(f\"Classes:{annots_dataset.analyze.classes}\")\n","        print(f\"Class counts:\\n{annots_dataset.analyze.class_counts}\")\n","        print(f\"Path to annotations:\\n{annots_dataset.path_to_annotations}\")\n","\n","        return annots_dataset\n","\n","    def combine_datasets(self, datasets):\n","        \"\"\"\n","        Combine multiple PyLabel datasets into a single dataset.\n","\n","        Parameters:\n","        - datasets (list): A list of Dataset objects to be combined.\n","\n","        Returns:\n","        - Dataset: The combined Pylabel dataset.\n","        \"\"\"\n","        combined_df = pd.concat([dataset.df for dataset in datasets], axis=0)\n","        print(f\"Number of images before dropna: {Dataset(combined_df).analyze.num_images}\")\n","        combined_df = combined_df.dropna(subset=['cat_name'])\n","        print(f\"Number of images after dropna: {Dataset(combined_df).analyze.num_images}\")\n","        combined_df.sort_values(by='img_filename', inplace=True)\n","        combined_df.reset_index(drop=True, inplace=True)\n","\n","        # Initialize img_id counter and previous filename\n","        current_img_id = 0\n","        previous_filename = None\n","\n","        # Iterate through rows and update img_id based on filename changes\n","        for index, row in combined_df.iterrows():\n","            current_filename = row['img_filename']\n","            if current_filename != previous_filename:\n","                current_img_id += 1\n","            combined_df.at[index, 'img_id'] = current_img_id\n","            previous_filename = current_filename\n","\n","        return Dataset(combined_df)\n","\n","    def check_class_fraction(self, dataset):\n","        \"\"\"\n","        Check class fraction for the train and test splits of the given dataset.\n","\n","        Parameters:\n","        - dataset (Dataset): The dataset to analyze.\n","        \"\"\"\n","        splits = dataset.df.groupby('split')\n","\n","        for split, df in splits:\n","            classes = Counter(df['cat_name'])\n","            total_samples = len(df)\n","            print(f\"\\nClass fraction for {split} dataset:\")\n","            for class_name, count in classes.items():\n","                fraction = (count / len(df))*100\n","                print(f\"{class_name}: {fraction:.4f}% ({count}/{total_samples} samples)\")\n","\n","if __name__ == \"__main__\":\n","    print(\"--------------------------\\nPipeline Script \\nLast Update: 3/3/2024 \\n-------------------------- \\n\\n\")\n","    # Define the paths\n","    home = os.getcwd() # Make sure inside the home directory of repo\n","    destination_path = f\"{home}/processed_yolo\"\n","    temp_path = os.path.join(home, \"temp\")\n","    raw_data_path = os.path.join(home, \"raw_data_test\")\n","\n","    # Copy the contents of raw_data to temp folder\n","    print(\"--------------------------\\n( 1 ) Creating 'temp' Folder\\n--------------------------\\n\")\n","    print(\"Copying raw_data to temp folder...\")\n","    shutil.copytree(raw_data_path, temp_path, dirs_exist_ok=True)\n","    print(\"Copying completed.\")\n","\n","    # Suppress warnings\n","    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n","\n","    processor = CocoDatasetProcessor(home)\n","    \n","    # Create array of JSON\n","    print(\"--------------------------\\n( 2 ) Preparing PyLabel COCO Dataset\\n--------------------------\\n\")\n","    users = ['user_1', 'user_2', 'user_3', 'user_4']\n","    suffixes = ['pre', 'post']\n","    \n","    datasets = []\n","    \n","    for user in users:\n","        for suffix in suffixes:\n","            image_directory = f\"{home}/temp/{suffix}_event/{user}\"\n","            \n","            # Check if the directory exists\n","            if not os.path.exists(image_directory):\n","                print(f\"Directory not found: {image_directory}. Skipping...\")\n","                continue\n","                \n","            processor.rename_images_with_suffix(image_directory, suffix)\n","            path_to_annots_json = f\"{home}/temp/{suffix}_event/{user}-{suffix}.json\"\n","\n","            # Check if the annotation file exists\n","            if not os.path.exists(path_to_annots_json):\n","                print(f\"\\n\\n{user}-{suffix}.json Not Found.\\n Skipping...\\n\\n\")\n","                continue\n","\n","            path_to_images = image_directory\n","            dataset = processor.prepare_coco_dataset(path_to_annots_json, path_to_images, user, suffix)\n","    \n","            # Modify img_filename column to add suffix in front of each filename\n","            dataset.df['img_filename'] = suffix + '_' + dataset.df['img_filename']\n","            \n","            datasets.append(dataset)\n","\n","    # Combine multiple input datasets\n","    print(\"--------------------------\\n( 3 ) Creating Dataset\\n--------------------------\\n\")\n","    processed_dataset = processor.combine_datasets(datasets)\n","\n","    # Split into Train and Test\n","    print(\"--------------------------\\n( 4 ) Splitting Dataset\\n--------------------------\\n\")\n","    #processed_dataset.splitter.StratifiedGroupShuffleSplit(train_pct=0.8, val_pct=0, test_pct=0.2, batch_size=1)\n","\n","    # Check class fraction\n","    print(\"--------------------------\\n( 5 ) Checking Splits Statistics\\n--------------------------\\n\")\n","    #processor.check_class_fraction(processed_dataset)\n","\n","    # Statistics\n","    print(\"\\n\\n\")\n","    print(\"--------------------------\\n( 6 ) Dataset Statistics\\n--------------------------\\n\")\n","    print(f\"Number of images: {processed_dataset.analyze.num_images}\")\n","    print(f\"Number of classes: {processed_dataset.analyze.num_classes}\")\n","    print(f\"Classes:{processed_dataset.analyze.classes}\")\n","    print(f\"Class counts:\\n{processed_dataset.analyze.class_counts}\")\n","    print(f\"Path to annotations:\\n{processed_dataset.path_to_annotations}\")\n","    print(\"\\n\\n\")\n","\n","    # Export for YOLO\n","    print(\"--------------------------\\n( 7 ) COCO to YOLO\\n--------------------------\\n\")\n","    print(\"Exporting to YOLO format...\")\n","    processed_dataset.export.ExportToYoloV5(output_path=f'{destination_path}/labels',\n","                                            yaml_file='dataset.yaml',\n","                                            cat_id_index = 0,\n","                                            copy_images=True,\n","                                            use_splits=True)\n","    \n","    # Remove the temporary directory\n","    shutil.rmtree(temp_path)\n","    print(\"--------------------------\\nPipeline Script End\\n--------------------------\\n\")\n"]}],"metadata":{"kernelspec":{"display_name":"ey-venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":2}
